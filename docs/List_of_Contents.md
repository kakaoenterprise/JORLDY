# List of Contents

### Algorithms

**Q-Value based**

- [Deep Q Network (DQN)](https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf)
- [Double DQN](https://arxiv.org/abs/1509.06461)
- [Dueling DQN](https://arxiv.org/abs/1511.06581)
- Multistep DQN

**Replay Buffer**

- [Prioritized Experience Replay (PER)](https://arxiv.org/abs/1511.05952)

**Distributional**

- [C51](https://arxiv.org/abs/1707.06887)
- [Quantile Regression DQN (QRDQN)](https://arxiv.org/abs/1710.10044)
- [Implicit Quantile Network (IQN)](https://arxiv.org/abs/1806.06923)

**Exploration**

- [Noisy Network](https://arxiv.org/abs/1706.10295)
- [Curiousity-driven Exploration (ICM)](https://arxiv.org/abs/1705.05363)
- [Random Network Distillation (RND)](https://arxiv.org/abs/1810.12894)

**Combination**

- [Rainbow [DQN, IQN]](https://arxiv.org/abs/1710.02298)

**Distributed**

- [APE-X](https://arxiv.org/pdf/1803.00933.pdf)
- [R2D2](https://openreview.net/pdf?id=r1lyTjAqYX)

**Policy Optimization, Actor-Critic**

- [REINFORCE [Discrete, Continuous]](https://people.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)
- [Deep Deterministic Policy Gradient](https://arxiv.org/abs/1509.02971)
- [Proximal Policy Optimization (PPO) [Discrete, Continuous]](https://arxiv.org/abs/1707.06347)
- [Soft Actor Critic (SAC) [Continuous]](https://arxiv.org/abs/1801.01290)
- [Maximum a posteriori Policy Optimization(MPO) [Discrete, Continuous]](https://arxiv.org/abs/1806.06920) 
- [V-MPO [Discrete, Continuous]](https://arxiv.org/abs/1909.12238)

---

### Environments

- [Gym classic control](https://gym.openai.com/envs/#classic_control) 
- [Gym Atari](https://gym.openai.com/envs/#atari) 
- [ML-Agents](https://github.com/Unity-Technologies/ml-agents) 
- [Procgen](https://github.com/openai/procgen)
- [Super Mario Bros](https://pypi.org/project/gym-super-mario-bros/)